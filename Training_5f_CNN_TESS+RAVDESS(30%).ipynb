{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18164,"status":"ok","timestamp":1709891837103,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"7agvzW2db_MM","outputId":"dd28734b-bf8f-44c6-a1b3-3865ee550a26"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709891837104,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"pTm1l2nTcPPg","outputId":"80288eff-fab3-4640-c9da-95810f406457"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1165,"status":"ok","timestamp":1709891838265,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"Rl-NKK5qcQVM"},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","import os\n","import time\n","import librosa\n","import librosa.display\n","import IPython\n","from IPython.display import Audio\n","from IPython.display import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sys\n","\n","import warnings\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3508,"status":"ok","timestamp":1709891841768,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"YnBQla3XcSi3"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class EmotionCNN(nn.Module):\n","    def __init__(self, num_emotions):\n","        super().__init__()\n","\n","        # Convolutional Layers\n","        self.conv1 = nn.Conv1d(1, 256, kernel_size=5, stride=1) # [batch size, 1, 193] -> [batch size, 256, 189]\n","        self.bn1 = nn.BatchNorm1d(256)\n","        self.relu1 = nn.ReLU()\n","\n","        self.conv2 = nn.Conv1d(256, 128, kernel_size=5, stride=1) # [batch size, 256, 189] -> [batch size, 128, 185]\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.relu2 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(0.1)\n","\n","        self.conv3 = nn.Conv1d(128, 128, kernel_size=5, stride=1) # [batch size, 128, 185] -> [batch size, 128, 181]\n","        self.bn3 = nn.BatchNorm1d(128)\n","        self.relu3 = nn.ReLU()\n","\n","        self.conv4 = nn.Conv1d(128, 128, kernel_size=5, stride=1) # [batch size, 128, 181] -> [batch size, 128, 177]\n","        self.bn4 = nn.BatchNorm1d(128)\n","        self.relu4 = nn.ReLU()\n","        self.maxpool = nn.MaxPool1d(kernel_size=8) # [batch size, 128, 177] -> [batch size, 128, 22]\n","\n","        self.conv5 = nn.Conv1d(128, 128, kernel_size=5, stride=1)\n","        self.bn5 = nn.BatchNorm1d(128)\n","        self.relu5 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(0.2)\n","\n","        self.conv6 = nn.Conv1d(128, 128, kernel_size=5, stride=1)\n","        self.bn6 = nn.BatchNorm1d(128)\n","        self.relu6 = nn.ReLU()\n","\n","        self.flatten = nn.Flatten()\n","        self.dropout3 = nn.Dropout(0.2)\n","\n","        # Fully Connected Layers\n","        self.fc = nn.Sequential(\n","            nn.Linear(1792, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, num_emotions),\n","        )\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        # Convolutional layers\n","        conv_embedding = self.relu1(self.bn1(self.conv1(x)))\n","        conv_embedding = self.dropout1(self.relu2(self.bn2(self.conv2(conv_embedding))))\n","        conv_embedding = self.relu3(self.bn3(self.conv3(conv_embedding)))\n","        conv_embedding = self.maxpool(self.relu4(self.bn4(self.conv4(conv_embedding))))\n","        conv_embedding = self.dropout2(self.relu5(self.bn5(self.conv5(conv_embedding))))\n","        conv_embedding = self.relu6(self.bn6(self.conv6(conv_embedding)))\n","        # Flatten\n","        conv_embedding = self.flatten(conv_embedding)\n","        conv_embedding = self.dropout3(conv_embedding)\n","\n","        # Fully Connected Layers\n","        output_logits = self.fc(conv_embedding)\n","        output_softmax = self.softmax(output_logits)\n","\n","        return output_logits, output_softmax\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709891841768,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"JqZ8JB9_cUCB"},"outputs":[],"source":["def loss_fnc(predictions, targets):\n","    return nn.CrossEntropyLoss()(input=predictions,target=targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709891841768,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"QRORzm2McVh0"},"outputs":[],"source":["def make_train_step(model, loss_fnc, optimizer):\n","    def train_step(X,Y):\n","        # set model to train mode\n","        model.train()\n","        # forward pass\n","        output_logits, output_softmax = model(X)\n","        predictions = torch.argmax(output_softmax,dim=1)\n","        accuracy = torch.sum(Y==predictions)/float(len(Y))\n","        # compute loss\n","        loss = loss_fnc(output_logits, Y)\n","        # compute gradients\n","        loss.backward()\n","        # update parameters and zero gradients\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        return loss.item(), accuracy*100\n","    return train_step"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709891841769,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"1Liw0UKVcXHK"},"outputs":[],"source":["def make_validate_fnc(model,loss_fnc):\n","    def validate(X,Y):\n","        with torch.no_grad():\n","            model.eval()\n","            output_logits, output_softmax = model(X)\n","            predictions = torch.argmax(output_softmax,dim=1)\n","            accuracy = torch.sum(Y==predictions)/float(len(Y))\n","            loss = loss_fnc(output_logits,Y)\n","        return loss.item(), accuracy*100, predictions\n","    return validate"]},{"cell_type":"markdown","metadata":{},"source":["## Load arrays (5 feature representation) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6536,"status":"ok","timestamp":1709891848299,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"as1YEk_xcYtZ","outputId":"44ad06c2-89cb-4d45-be60-caad83674b9a"},"outputs":[],"source":["X_train = np.load(file=\"/content/drive/MyDrive/  /xtrain.npy\")\n","X_test = np.load(file=\"/content/drive/MyDrive/  /xtest.npy\")\n","X_val = np.load(file=\"/content/drive/MyDrive/  /xval.npy\")\n","\n","Y_train = np.load(file=\"/content/drive/MyDrive/  /ytrain.npy\")\n","Y_test = np.load(file=\"/content/drive/MyDrive/  /ytest.npy\")\n","Y_val = np.load(file=\"/content/drive/MyDrive/  /yval.npy\")\n","\n","X_train.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Set hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2023,"status":"ok","timestamp":1709891850309,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"sRhiH5gacn5t","outputId":"e2e499f1-bdb7-41c9-d373-366ce08cd891"},"outputs":[],"source":["EMOTIONS = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 0:'surprise'}\n","EPOCHS = 250\n","DATASET_SIZE = X_train.shape[0]\n","BATCH_SIZE = 64 # smaller batch size improves val acc (?)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Selected device is {}'.format(device))\n","model = EmotionCNN(num_emotions=len(EMOTIONS)).to(device)\n","print('Number of trainable params: ',sum(p.numel() for p in model.parameters()))\n","\n","OPTIMIZER = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n","# OPTIMIZER = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3, momentum=0.8)\n","# OPTIMIZER = torch.optim.SGD(model.parameters(), lr=0.0001, weight_decay=1e-5, momentum=0.8)\n","# OPTIMIZER = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=1e-5)\n","# OPTIMIZER = torch.optim.RMSprop(model.parameters(), lr=0.00001, weight_decay=1e-6)\n","\n","train_step = make_train_step(model, loss_fnc, optimizer=OPTIMIZER)\n","validate = make_validate_fnc(model,loss_fnc)\n","losses = []\n","val_losses = []"]},{"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354866,"status":"ok","timestamp":1709892215928,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"Ye-703OGcwU-","outputId":"2ba0955e-d57f-4146-8d4e-4bc944b03440"},"outputs":[],"source":["start = time.time()\n","for epoch in range(EPOCHS):\n","    # shuffle data\n","    start_epoch = time.time()\n","    ind = np.random.permutation(DATASET_SIZE)\n","    X_train = X_train[ind,:,:]\n","    Y_train = Y_train[ind]\n","    epoch_acc = 0\n","    epoch_loss = 0\n","    iters = int(DATASET_SIZE / BATCH_SIZE)\n","    for i in range(iters):\n","        batch_start = i * BATCH_SIZE\n","        batch_end = min(batch_start + BATCH_SIZE, DATASET_SIZE)\n","        actual_batch_size = batch_end-batch_start\n","        X = X_train[batch_start:batch_end,:,:]\n","        Y = Y_train[batch_start:batch_end]\n","        X_tensor = torch.tensor(X,device=device).float()\n","        Y_tensor = torch.tensor(Y, dtype=torch.long,device=device)\n","        loss, acc = train_step(X_tensor,Y_tensor)\n","        epoch_acc += acc*actual_batch_size/DATASET_SIZE\n","        epoch_loss += loss*actual_batch_size/DATASET_SIZE\n","        print(f\"\\r Epoch {epoch}: iteration {i}/{iters}\",end='')\n","    X_val_tensor = torch.tensor(X_val,device=device).float()\n","    Y_val_tensor = torch.tensor(Y_val,dtype=torch.long,device=device)\n","    val_loss, val_acc, predictions = validate(X_val_tensor,Y_val_tensor)\n","    losses.append(epoch_loss)\n","    val_losses.append(val_loss)\n","    elapsed_epoch = time.time() - start_epoch\n","    print('')\n","    print(f\"Epoch {epoch} --> loss:{epoch_loss:.4f}, acc:{epoch_acc:.2f}%, val_loss:{val_loss:.4f}, \"\n","        f\"val_acc:{val_acc:.2f}%, time:{elapsed_epoch:.2f}sec\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1709892242443,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"HqELJPcrcxwV","outputId":"d564dda0-faae-4a8b-e833-5525fd3523bf"},"outputs":[],"source":["elapsed = time.time() - start\n","print(f\"Total training time:{elapsed:.2f}sec\")"]},{"cell_type":"markdown","metadata":{"id":"1BcbBPjyc4ww"},"source":["## Plot loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":728,"status":"ok","timestamp":1709892246141,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"6k8FhGECc0nm","outputId":"15730985-1a6c-4018-f75d-7a3bcf19df9b"},"outputs":[],"source":["plt.plot(losses,'b')\n","plt.plot(val_losses,'r')\n","plt.legend(['train loss','val loss'])"]},{"cell_type":"markdown","metadata":{"id":"ilF-FZfYc9Ws"},"source":["## Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1709892297391,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"hBuAHSKYdCK1","outputId":"3f9032a6-4b12-4513-ef56-160c6ba64cd8"},"outputs":[],"source":["SAVE_PATH = os.path.join(os.getcwd(),'/content/drive/MyDrive/ ')\n","torch.save(model.state_dict(),os.path.join(SAVE_PATH,'5f_base_Tess+Ravdess(30%)_model.pt'))\n","print('Model is saved to {}'.format(os.path.join(SAVE_PATH,'5f_base_Tess+Ravdess(30%)_model.pt')))"]},{"cell_type":"markdown","metadata":{},"source":["## Load and test model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1709892306430,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"xFI4NeOlKK54","outputId":"bb39cff2-3f91-4e0b-e91e-3048ba96816a"},"outputs":[],"source":["LOAD_PATH = os.path.join(os.getcwd(),'/content/drive/MyDrive/ ')\n","model = EmotionCNN(len(EMOTIONS))\n","model.load_state_dict(torch.load(os.path.join(LOAD_PATH,'5f_base_Tess+Ravdess(30%)_model.pt')))\n","print('Model is loaded from {}'.format(os.path.join(LOAD_PATH,'5f_base_Tess+Ravdess(30%)_model.pt')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1227,"status":"ok","timestamp":1709892313812,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"od1fbB0ypYyJ","outputId":"4d82166d-ea1c-4437-f3d4-a412682ec0d8"},"outputs":[],"source":["Ravdess_X_test = np.load(file=\"/content/drive/MyDrive/ /Ravdess_xtest.npy\")\n","Ravdess_Y_test = np.load(file=\"/content/drive/MyDrive/ /Ravdess_ytest.npy\")\n","\n","print(Ravdess_X_test.shape)\n","print(Ravdess_Y_test.shape)\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","validate = make_validate_fnc(model,loss_fnc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1965,"status":"ok","timestamp":1709892322422,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"1nmU9oJIKIP-","outputId":"96a580ce-fc80-4b71-df31-9b39259602e2"},"outputs":[],"source":["device = 'cpu'\n","print('Selected device is {}'.format(device))\n","\n","X_test = Ravdess_X_test\n","Y_test = Ravdess_Y_test\n","\n","start = time.time()\n","X_test_tensor = torch.tensor(X_test,device=device).float()\n","Y_test_tensor = torch.tensor(Y_test,dtype=torch.long,device=device)\n","test_loss, test_acc, predictions = validate(X_test_tensor, Y_test_tensor)\n","elapsed = time.time() - start\n","print(f'Test loss is {test_loss:.3f}')\n","print(f'Test accuracy is {test_acc:.2f}%')\n","print(f\"Total test time:{elapsed:.3f}sec\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"elapsed":888,"status":"ok","timestamp":1709892351863,"user":{"displayName":"るい","userId":"15353790188108276038"},"user_tz":-480},"id":"sXk_Ht8GKh__","outputId":"39bf1af3-a45a-4458-ef72-b102fd596712"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","\n","predictions = predictions.cpu().numpy()\n","cm = confusion_matrix(Y_test, predictions)\n","names = [EMOTIONS[ind] for ind in range(len(EMOTIONS))]\n","df_cm = pd.DataFrame(cm, index=names, columns=names)\n","# plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n","plt.show()\n","\n","# Rows are the inputs, columns are the classification"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOh5YE8nIprBGdsqd97JK8W","gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
