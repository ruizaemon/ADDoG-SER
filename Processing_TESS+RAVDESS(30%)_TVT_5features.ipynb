{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing audio files into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes for the two datasets\n",
    "# 3 columns: path, emotion label, domain label (RAVDESS 0, TESS 1)\n",
    "\n",
    "Ravdess = \"/RAVDESS/audio_speech_actors_01-24/\" # path to RAVDESS dataset\n",
    "Tess = \"/TESS/\" # path to TESS dataset\n",
    "\n",
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "domain_column = []\n",
    "\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0] # e.g., 03-01-06-01-01-01-01\n",
    "        part = part.split('-')\n",
    "        # extract the third section as emotion\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess + dir + '/' + file)\n",
    "        domain_column.append(0) # domain 0\n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotion'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "domain_df = pd.DataFrame(domain_column, columns=['Domain'])\n",
    "Ravdess_df = pd.concat([path_df, emotion_df, domain_df], axis=1)\n",
    "\n",
    "Ravdess_df.Emotion.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', \\\n",
    "                            7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.Emotion.replace({'neutral':1, 'calm':2, 'happy':3, 'sad':4, 'angry':5, 'fear':6, \\\n",
    "                          'disgust':7, 'surprise':0}, inplace=True)\n",
    "\n",
    "# -------------------------------------------------------------------------------- #\n",
    "\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "domain_column = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part == 'ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        domain_column.append(1) # domain 1\n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotion'])\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "domain_df = pd.DataFrame(domain_column, columns=['Domain'])\n",
    "Tess_df = pd.concat([path_df, emotion_df, domain_df], axis=1)\n",
    "\n",
    "Tess_df.Emotion.replace({'neutral':1, 'calm':2, 'happy':3, 'sad':4, 'angry':5, 'fear':6, \\\n",
    "                          'disgust':7, 'surprise':0}, inplace=True)\n",
    "\n",
    "# combined_df = pd.concat([Ravdess_df, Tess_df], axis=0, ignore_index=True)\n",
    "# combined_df.Emotion.replace({'neutral':1, 'calm':2, 'happy':3, 'sad':4, 'angry':5, 'fear':6, \\\n",
    "#                             'disgust':7, 'surprise':0}, inplace=True)\n",
    "\n",
    "# combined_df\n",
    "\n",
    "Ravdess_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('Count of Emotions', size=16)\n",
    "# sns.countplot(x=Tess_df[\"Emotion\"])\n",
    "# plt.ylabel('Count', size=12)\n",
    "# plt.xlabel('Emotions', size=12)\n",
    "# sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "# plt.show()\n",
    "\n",
    "# TESS does not have 'calm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 30% of RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take only 54 x 8 = 432 of RAVDESS data \n",
    "\n",
    "# Grouping the DataFrame by 'Emotion'\n",
    "grouped_df = Ravdess_df.groupby('Emotion')\n",
    "\n",
    "sampled_dfs = []\n",
    "remaining_dfs = []\n",
    "\n",
    "# Loop through each group (emotion)\n",
    "for emotion, group_df in grouped_df:\n",
    "    # If there are fewer than 80 samples for an emotion, use all available samples\n",
    "    if len(group_df) <= 54:\n",
    "        sampled_df = group_df\n",
    "        remaining_df = pd.DataFrame() # Empty DataFrame for remaining rows\n",
    "    else:\n",
    "        # Randomly sample 80 rows for each emotion\n",
    "        sampled_df = group_df.sample(n=54, random_state=42)  # Set random_state for reproducibility\n",
    "        remaining_df = group_df.drop(sampled_df.index)\n",
    "    sampled_dfs.append(sampled_df)\n",
    "    remaining_dfs.append(remaining_df)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "Ravdess_30p_df = pd.concat(sampled_dfs)\n",
    "Ravdess_test_df = pd.concat(remaining_dfs)\n",
    "\n",
    "# Reset index\n",
    "Ravdess_30p_df.reset_index(drop=True, inplace=True)\n",
    "Ravdess_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(Ravdess_30p_df)\n",
    "print(Ravdess_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([Tess_df, Ravdess_30p_df], axis=0, ignore_index=True)\n",
    "combined_df.Emotion.replace({'neutral':1, 'calm':2, 'happy':3, 'sad':4, 'angry':5, 'fear':6, \\\n",
    "                            'disgust':7, 'surprise':0}, inplace=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(x=combined_df[\"Emotion\"])\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and trimming signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 48000\n",
    "\n",
    "ravdess_30p_signals = []\n",
    "for i, file_path in enumerate(Ravdess_30p_df.Path):\n",
    "    audio, sample_rate = librosa.load(file_path, duration=3.5, offset=0, sr=SAMPLE_RATE)\n",
    "    signal = np.zeros((int(SAMPLE_RATE*3.5,)))\n",
    "\n",
    "    # Use librosa.effects.trim to trim silent sections\n",
    "    audio_trimmed, index = librosa.effects.trim(audio, top_db=18)  # Adjust 'top_db' as needed\n",
    "\n",
    "    signal[:len(audio_trimmed)] = audio_trimmed\n",
    "    ravdess_30p_signals.append(signal)\n",
    "    print(\"\\r Processed {}/{} {} files\".format(i,len(Ravdess_30p_df), \"Ravdess 30%\"),end='')\n",
    "ravdess_30p_signals = np.stack(ravdess_30p_signals,axis=0)\n",
    "print('\\n')\n",
    "\n",
    "ravdess_test_signals = []\n",
    "for i, file_path in enumerate(Ravdess_test_df.Path):\n",
    "    audio, sample_rate = librosa.load(file_path, duration=3.5, offset=0, sr=SAMPLE_RATE)\n",
    "    signal = np.zeros((int(SAMPLE_RATE*3.5,)))\n",
    "\n",
    "    # Use librosa.effects.trim to trim silent sections\n",
    "    audio_trimmed, index = librosa.effects.trim(audio, top_db=18)  # Adjust 'top_db' as needed\n",
    "\n",
    "    signal[:len(audio_trimmed)] = audio_trimmed\n",
    "    ravdess_test_signals.append(signal)\n",
    "    print(\"\\r Processed {}/{} {} files\".format(i,len(Ravdess_test_df), \"Ravdess test\"),end='')\n",
    "ravdess_test_signals = np.stack(ravdess_test_signals,axis=0)\n",
    "\n",
    "tess_signals = []\n",
    "for i, file_path in enumerate(Tess_df.Path):\n",
    "    audio, sample_rate = librosa.load(file_path, duration=3.5, offset=0, sr=SAMPLE_RATE)\n",
    "    signal = np.zeros((int(SAMPLE_RATE*3.5,)))\n",
    "    audio_trimmed, index = librosa.effects.trim(audio, top_db=18)  # Adjust 'top_db' as needed\n",
    "    signal[:len(audio_trimmed)] = audio_trimmed\n",
    "    tess_signals.append(signal)\n",
    "    print(\"\\r Processed {}/{} {} files\".format(i,len(Tess_df), \"Tess\"),end='')\n",
    "tess_signals = np.stack(tess_signals,axis=0)\n",
    "\n",
    "total_TrVal_signals = np.vstack((tess_signals, ravdess_30p_signals))\n",
    "print('\\n', total_TrVal_signals.shape)\n",
    "print(ravdess_test_signals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = combined_df['Domain'].to_numpy(dtype=np.int32)\n",
    "# Z, Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 0:'surprise'}\n",
    "X = total_TrVal_signals\n",
    "Z = combined_df['Domain'].to_numpy(dtype=np.int32)\n",
    "train_ind,test_ind,val_ind = [],[],[]\n",
    "X_train,X_val,X_test = [],[],[] # signal\n",
    "Y_train,Y_val,Y_test = [],[],[] # emotion label\n",
    "Z_train,Z_val,Z_test = [],[],[] # domain label\n",
    "\n",
    "Ravdess_X_test = ravdess_test_signals\n",
    "Ravdess_Y_test = Ravdess_test_df['Emotion'].values\n",
    "Ravdess_Z_test = Ravdess_test_df['Domain'].values\n",
    "\n",
    "print(f'Ravdess_X_test:{Ravdess_X_test.shape}, Ravdess_Y_test:{Ravdess_Y_test.shape}, Ravdess_Z_test:{Ravdess_Z_test.shape}')\n",
    "\n",
    "for emotion in range(len(EMOTIONS)):\n",
    "    emotion_ind = list(combined_df.loc[combined_df.Emotion==emotion,'Emotion'].index)\n",
    "    emotion_ind = np.random.permutation(emotion_ind)\n",
    "    m = len(emotion_ind)\n",
    "    ind_train = emotion_ind[:int(0.8*m)]\n",
    "    ind_val = emotion_ind[int(0.8*m):int(0.9*m)]\n",
    "    ind_test = emotion_ind[int(0.9*m):]\n",
    "\n",
    "    X_train.append(X[ind_train,:])\n",
    "    Y_train.append(np.array([emotion]*len(ind_train),dtype=np.int32))\n",
    "    Z_train.append(Z[ind_train])\n",
    "\n",
    "    X_val.append(X[ind_val,:])\n",
    "    Y_val.append(np.array([emotion]*len(ind_val),dtype=np.int32))\n",
    "    Z_val.append(Z[ind_val])\n",
    "\n",
    "    X_test.append(X[ind_test,:])\n",
    "    Y_test.append(np.array([emotion]*len(ind_test),dtype=np.int32))\n",
    "    Z_test.append(Z[ind_test])\n",
    "\n",
    "    train_ind.append(ind_train)\n",
    "    test_ind.append(ind_test)\n",
    "    val_ind.append(ind_val)\n",
    "\n",
    "X_train = np.concatenate(X_train,0)\n",
    "X_val = np.concatenate(X_val,0)\n",
    "X_test = np.concatenate(X_test,0)\n",
    "Y_train = np.concatenate(Y_train,0)\n",
    "Y_val = np.concatenate(Y_val,0)\n",
    "Y_test = np.concatenate(Y_test,0)\n",
    "Z_train = np.concatenate(Z_train,0)\n",
    "Z_val = np.concatenate(Z_val,0)\n",
    "Z_test = np.concatenate(Z_test,0)\n",
    "\n",
    "train_ind = np.concatenate(train_ind,0)\n",
    "val_ind = np.concatenate(val_ind,0)\n",
    "test_ind = np.concatenate(test_ind,0)\n",
    "print(f'X_train:{X_train.shape}, Y_train:{Y_train.shape}, Z_train:{Z_train.shape}')\n",
    "print(f'X_val:{X_val.shape}, Y_val:{Y_val.shape}, Z_val:{Z_val.shape}')\n",
    "print(f'X_test:{X_test.shape}, Y_test:{Y_test.shape}, Z_test:{Z_test.shape}')\n",
    "# check if all are unique\n",
    "unique, count = np.unique(np.concatenate([train_ind,test_ind,val_ind],0), return_counts=True)\n",
    "print(\"Number of unique indexes is {}, out of {}\".format(sum(count==1), X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAWGN(signal, num_bits=16, augmented_num=2, snr_low=15, snr_high=30):\n",
    "    signal_len = len(signal)\n",
    "    # Generate White Gaussian noise\n",
    "    noise = np.random.normal(size=(augmented_num, signal_len))\n",
    "    # Normalize signal and noise\n",
    "    norm_constant = 2.0**(num_bits-1)\n",
    "    signal_norm = signal / norm_constant\n",
    "    noise_norm = noise / norm_constant\n",
    "    # Compute signal and noise power\n",
    "    s_power = np.sum(signal_norm ** 2) / signal_len\n",
    "    n_power = np.sum(noise_norm ** 2, axis=1) / signal_len\n",
    "    # Random SNR: Uniform [15, 30] in dB\n",
    "    target_snr = np.random.randint(snr_low, snr_high)\n",
    "    # Compute K (covariance matrix) for each noise\n",
    "    K = np.sqrt((s_power / n_power) * 10 ** (- target_snr / 10))\n",
    "    K = np.ones((signal_len, augmented_num)) * K\n",
    "    # Generate noisy signal\n",
    "    return signal + K.T * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting training set with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_signals = []\n",
    "aug_emotion_labels = []\n",
    "aug_domain_labels = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    signal = X_train[i,:]\n",
    "    augmented_signals = addAWGN(signal)\n",
    "    for j in range(augmented_signals.shape[0]):\n",
    "        aug_emotion_labels.append(combined_df.loc[i,\"Emotion\"])\n",
    "        aug_domain_labels.append(combined_df.loc[i,\"Domain\"])\n",
    "        aug_signals.append(augmented_signals[j,:])\n",
    "        # data_path = data_path.append(data_path.iloc[i], ignore_index=True)\n",
    "        pd.concat([combined_df, combined_df.iloc[i]])\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_train.shape[0]),end='')\n",
    "aug_signals = np.stack(aug_signals,axis=0)\n",
    "X_train = np.concatenate([X_train,aug_signals],axis=0)\n",
    "aug_emotion_labels = np.stack(aug_emotion_labels,axis=0)\n",
    "Y_train = np.concatenate([Y_train,aug_emotion_labels])\n",
    "aug_domain_labels = np.stack(aug_domain_labels,axis=0)\n",
    "Z_train = np.concatenate([Z_train,aug_domain_labels])\n",
    "print('')\n",
    "print(f'X_train:{X_train.shape}, Y_train:{Y_train.shape}, Z_train:{Z_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_of_nested_list(double_nested_list):\n",
    "    averages = []\n",
    "\n",
    "    # Iterate over the inner lists\n",
    "    for inner_list in double_nested_list:\n",
    "        # Calculate the average of each inner list\n",
    "        if len(inner_list) > 0:\n",
    "            avg = [sum(inner_list) / len(inner_list)]\n",
    "            averages.append(avg)\n",
    "        else:\n",
    "            # Handle the case of an empty inner list (avoid division by zero)\n",
    "            averages.append(0.0)\n",
    "\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "def getMFCC(audio, sample_rate, n_mfcc):\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "    mfcc_db = librosa.power_to_db(mfcc, ref=np.max)\n",
    "    result = scaler.fit_transform(mfcc_db)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMELspectrogram(audio, sample_rate, n_mels):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    result = scaler.fit_transform(mel_spec_db)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChroma(audio, sample_rate, n_chroma):\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate, n_chroma=n_chroma)\n",
    "    chroma_db = librosa.power_to_db(chroma, ref=np.max)\n",
    "    result = scaler.fit_transform(chroma_db)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpectralContrast(audio, sample_rate, n_bands):\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate, n_bands=n_bands)\n",
    "    spectral_contrast_db = librosa.power_to_db(spectral_contrast, ref=np.max)\n",
    "    result = scaler.fit_transform(spectral_contrast_db)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTonnetz(audio, sample_rate):\n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(audio), sr=sample_rate)\n",
    "    # tonnetz_db = librosa.power_to_db(tonnetz, ref=np.max)\n",
    "    result = scaler.fit_transform(tonnetz)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 feature representation of audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_feature_transform(audio, sample_rate):\n",
    "\n",
    "    # Extract MFCCs (Mel-frequency cepstral coefficients)\n",
    "    mfccs = getMFCC(audio, sample_rate, 20) # (20x188)\n",
    "    mfccs = avg_of_nested_list(mfccs) # (20, 1)\n",
    "\n",
    "    # Extract Mel-scaled spectrogram (N frequency bins)\n",
    "    mel_spectrogram = getMELspectrogram(audio, sample_rate, 148) # (148x188)\n",
    "    mel_spectrogram = avg_of_nested_list(mel_spectrogram)\n",
    "\n",
    "    # Extract Chromagram (12 bins)\n",
    "    chromagram = getChroma(audio, sample_rate, 12) # (12x188)\n",
    "    chromagram = avg_of_nested_list(chromagram)\n",
    "\n",
    "    # Extract Spectral contrast feature (6 bins)\n",
    "    spectral_contrast = getSpectralContrast(audio, sample_rate, 6) # 5-7\n",
    "    spectral_contrast = avg_of_nested_list(spectral_contrast)\n",
    "\n",
    "    # Extract Tonnetz representation (6 dimensions)\n",
    "    tonnetz = getTonnetz(audio, sample_rate)\n",
    "    tonnetz = avg_of_nested_list(tonnetz)\n",
    "\n",
    "    # ---------  20 + 148 + 12 + 7 + 6 = 193  ----------- #\n",
    "\n",
    "    # Stack the features vertically (along the rows)\n",
    "    combined_features = np.vstack((mfccs, mel_spectrogram, chromagram, spectral_contrast, tonnetz)) # 193x1\n",
    "    combined_features = combined_features.transpose() # 1x193\n",
    "    return combined_features\n",
    "\n",
    "# Test\n",
    "emotion = 1\n",
    "path = np.array(combined_df.Path[combined_df.Emotion==emotion])[50]\n",
    "print(path)\n",
    "audio, sample_rate = librosa.load(combined_df.loc[0,'Path'], duration=3.5, sr=SAMPLE_RATE)\n",
    "signal = np.zeros((int(SAMPLE_RATE*3.5,)))\n",
    "signal[:len(audio)] = audio\n",
    "five_features = five_feature_transform(signal, SAMPLE_RATE)\n",
    "print('5 features transform shape: ', five_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_features_train = []\n",
    "print(\"Calculating 5 features for train set\")\n",
    "for i in range(X_train.shape[0]):\n",
    "    five_feature = five_feature_transform(X_train[i,:], sample_rate=SAMPLE_RATE)\n",
    "    five_features_train.append(five_feature)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_train.shape[0]),end='')\n",
    "print('')\n",
    "five_features_train = np.stack(five_features_train,axis=0)\n",
    "del X_train\n",
    "X_train = five_features_train\n",
    "\n",
    "five_features_val = []\n",
    "print(\"Calculating 5 features for val set\")\n",
    "for i in range(X_val.shape[0]):\n",
    "    five_feature = five_feature_transform(X_val[i,:], sample_rate=SAMPLE_RATE)\n",
    "    five_features_val.append(five_feature)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_val.shape[0]),end='')\n",
    "print('')\n",
    "five_features_val = np.stack(five_features_val,axis=0)\n",
    "del X_val\n",
    "X_val = five_features_val\n",
    "\n",
    "five_features_test = []\n",
    "print(\"Calculating 5 features for test set\")\n",
    "for i in range(X_test.shape[0]):\n",
    "    five_feature = five_feature_transform(X_test[i,:], sample_rate=SAMPLE_RATE)\n",
    "    five_features_test.append(five_feature)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_test.shape[0]),end='')\n",
    "print('')\n",
    "five_features_test = np.stack(five_features_test,axis=0)\n",
    "del X_test\n",
    "X_test = five_features_test\n",
    "\n",
    "Ravdess_five_features_test = []\n",
    "print(\"Calculating 5 features for test set\")\n",
    "for i in range(Ravdess_X_test.shape[0]):\n",
    "    five_feature = five_feature_transform(Ravdess_X_test[i,:], sample_rate=SAMPLE_RATE)\n",
    "    Ravdess_five_features_test.append(five_feature)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,Ravdess_X_test.shape[0]),end='')\n",
    "print('')\n",
    "Ravdess_five_features_test = np.stack(Ravdess_five_features_test,axis=0)\n",
    "del Ravdess_X_test\n",
    "Ravdess_X_test = Ravdess_five_features_test\n",
    "\n",
    "print(f'X_train:{X_train.shape}, Y_train:{Y_train.shape}, Z_train:{Z_train.shape}')\n",
    "print(f'X_val:{X_val.shape}, Y_val:{Y_val.shape}, Z_val:{Z_val.shape}')\n",
    "print(f'X_test:{X_test.shape}, Y_test:{Y_test.shape}, Z_test:{Z_test.shape}')\n",
    "print(f'Ravdess_X_test:{Ravdess_X_test.shape}, Ravdess_Y_test:{Ravdess_Y_test.shape}, Ravdess_Z_test:{Ravdess_Z_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.expand_dims(X_train,1)\n",
    "# X_val = np.expand_dims(X_val,1)\n",
    "# X_test = np.expand_dims(X_test,1)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# b,c,h,w = X_train.shape\n",
    "# X_train = np.reshape(X_train, newshape=(b,-1))\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_train = np.reshape(X_train, newshape=(b,c,h,w))\n",
    "# print('Shape of X_train: ',X_train.shape)\n",
    "\n",
    "# b,c,h,w = X_test.shape\n",
    "# X_test = np.reshape(X_test, newshape=(b,-1))\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_test = np.reshape(X_test, newshape=(b,c,h,w))\n",
    "# print('Shape of X_test: ',X_test.shape)\n",
    "\n",
    "# b,c,h,w = X_val.shape\n",
    "# X_val = np.reshape(X_val, newshape=(b,-1))\n",
    "# X_val = scaler.transform(X_val)\n",
    "# X_val = np.reshape(X_val, newshape=(b,c,h,w))\n",
    "# print('Shape of X_val: ',X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/xtrain.npy\", arr=X_train)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/xval.npy\", arr=X_val)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/xtest.npy\", arr=X_test)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/ytrain.npy\", arr=Y_train)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/yval.npy\", arr=Y_val)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/ytest.npy\", arr=Y_test)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/ztrain.npy\", arr=Z_train)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/zval.npy\", arr=Z_val)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/ztest.npy\", arr=Z_test)\n",
    "\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/Ravdess_xtest.npy\", arr=Ravdess_X_test)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/Ravdess_ytest.npy\", arr=Ravdess_Y_test)\n",
    "np.save(file=\"/TESS+RAVDESS(30%)_TVT_5features/Ravdess_ztest.npy\", arr=Ravdess_Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
